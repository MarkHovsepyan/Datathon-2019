{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, f1_score\n",
    "import pandas as pd\n",
    "from statistics import harmonic_mean\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_class_dct(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    ids = list(df['ID'])\n",
    "    labels = list(df['Label'])\n",
    "    return dict(zip(ids, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_mixed_dct(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    ids = list(df['FileName'])\n",
    "    labels = list(df['Label'])\n",
    "    return dict(zip(ids, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_lists(dct_pred, dct_true):\n",
    "    keys = list(dct_true.keys())\n",
    "    pred = []\n",
    "    true = []\n",
    "    for key in keys:\n",
    "        pred.append(dct_pred[key])\n",
    "        true.append(dct_true[key])\n",
    "    return pred, true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SeperateFiles(files):\n",
    "    mixed = {}\n",
    "    tel_no_tel = {}\n",
    "    for file in files:    \n",
    "        splitted = file.split('test_mixed_')\n",
    "        if splitted[0] == '':\n",
    "            name = splitted[-1].split('.')[0]\n",
    "            mixed[str(name)] = file\n",
    "        else:\n",
    "            name = file.split('test_tel_no-tel_')[-1].split('.')[0]\n",
    "            tel_no_tel[str(name)] = file\n",
    "    return mixed, tel_no_tel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R_squared(true, pred):\n",
    "    score = r2_score(true, pred)\n",
    "    return score\n",
    "#    if score < 0:\n",
    "#        return 0\n",
    "#    else:\n",
    "#        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(pred_length, pred_classification, true_length, true_classification):\n",
    "    R2 = R_squared(true_length, pred_length)\n",
    "    F1 = f1_score(true_classification, pred_classification)\n",
    "    if R2>0:\n",
    "        Accuracy = harmonic_mean([R2, F1])\n",
    "    else:\n",
    "        Accuracy = 0\n",
    "    result = {'R_squared': R2, 'F1_score': F1, 'Accuracy': Accuracy}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRUE_LENGTH_dct = return_mixed_dct('test_mixed_labeled.csv')\n",
    "TRUE_TELOMERES_dct = return_class_dct('test_data_labeled.csv') \n",
    "\n",
    "def Accuracy_i(mixed_file, tel_no_tel_file,\n",
    "               true_length_dct = TRUE_LENGTH_dct, true_classification_dct = TRUE_TELOMERES_dct):\n",
    "    pred_length_dct = return_mixed_dct(mixed_file)\n",
    "    pred_classification_dct = return_class_dct(tel_no_tel_file)\n",
    "    \n",
    "    pred_length, true_length = return_lists(pred_length_dct, true_length_dct)\n",
    "    pred_classification, true_classification = return_lists(pred_classification_dct, true_classification_dct)\n",
    "    return Accuracy(pred_length, pred_classification, true_length, true_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Results(path):\n",
    "    \n",
    "    files = os.listdir(path)\n",
    "    mixed_files, tel_no_tel_files = SeperateFiles(files)\n",
    "    \n",
    "    if len(mixed_files) != len(tel_no_tel_files):\n",
    "        return \"Files are messed up!\"\n",
    "        \n",
    "    R_squared = []\n",
    "    F1_score = []\n",
    "    Accuracy = []\n",
    "        \n",
    "    names = list(mixed_files.keys())\n",
    "    \n",
    "    print(names)\n",
    "    for i, name in enumerate(names):\n",
    "        print(name)\n",
    "        \n",
    "        mixed_file = mixed_files[name]\n",
    "        tel_no_tel_file = tel_no_tel_files[name]\n",
    "\n",
    "        result_i = Accuracy_i(path + mixed_file, path + tel_no_tel_file)\n",
    "\n",
    "        R_squared.append(result_i['R_squared'])\n",
    "        F1_score.append(result_i['F1_score'])\n",
    "        Accuracy.append(result_i['Accuracy'])\n",
    "        \n",
    "        print(name, \":\", R_squared[i], \" \", F1_score[i], \" \", Accuracy[i])\n",
    "        \n",
    "    results = pd.DataFrame({\"Name\":names, \"R_squared\":R_squared, \"F1_score\":F1_score, \"Accuracy\":Accuracy })\n",
    "    results.to_csv(\"Results.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Submissions/'\n",
    "Results(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NiTrio - classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nitrio_class = 'Submissions_all/Submissions_Dec_10_2019/NiTrio/test_tel_no-tel_NiTrio.csv'\n",
    "nitrio_dct = return_class_dct(nitrio_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nitrio_pred, nitrio_true = return_lists(nitrio_dct, TRUE_TELOMERES_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(nitrio_true, nitrio_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nutcall",
   "language": "python",
   "name": "nutcall"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
